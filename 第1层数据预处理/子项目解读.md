# 第1层数据预处理｜商品/评论表合并与清洗子项目解读

> 说明：本文中出现的相对路径，默认以项目根目录 `E:\PycharmProjects\三创赛` 为基准。

## 1. 子项目定位（在全链路中的作用）

本层把爬虫产出的多批次原始表（商品表、评论表）**合并→去重→结构化清洗→生成分析用主表/事实表**，为后续 NLP、建模、聚类、知识图谱提供“可直接读取”的干净数据。

- 上游：`amazon_spasers_v2.0/`（或其它渠道导出的 `products-*.csv`、`reviews-*.csv`）
- 下游：
  - `第二层NLP处理/`（评论文本与产品维表）
  - `第三层预测建模/`、`第四层预测建模_v3/`、`第五层聚类分析/`
  - `知识图谱分析与关联层/`

---

## 2. 本层使用的数据（输入文件）

工作目录：`第1层数据预处理/`

### 2.1 原始/分批抓取数据

- 商品表：`products-1-28.csv`、`products.csv`、`products-1-10.csv`
- 评论表：`reviews-1-28.csv`、`reviews-1-10.csv`

### 2.2 合并去重后的中间产物（本层生成）

- `merged_products_unique_asin.csv`（按 `asin` 去重，保留最新 `updated_at`）
- `merged_reviews_unique_review_id.csv`（按 `review_id` 去重，保留最新 `created_at`）

> 数据规模（当前目录现有产物统计）：
> - 商品：约 946 个（`merged_products_unique_asin.csv`）
> - 评论：约 2218 条（`merged_reviews_unique_review_id.csv`）

---

## 3. 核心脚本与做了什么（逐文件解读）

### 3.1 `商品表合并.py`

**解决问题**：多批次商品抓取会重复同一 ASIN（信息更新），需要“保留最新版本”。

**做法**：

- 读取 `products-1-28.csv / products.csv / products-1-10.csv`
- 合并后按 `updated_at` 降序排序
- 以 `asin` 去重，保留 `updated_at` 最新的记录

**输出**：`merged_products_unique_asin.csv`

### 3.2 `商品评论表合并.py`

**解决问题**：多批次评论抓取会重复同一 `review_id`，也可能列结构不一致（如缺 `brand`）。

**做法**：

- 读取 `reviews-1-28.csv / reviews-1-10.csv`
- 若缺失 `brand` 列则补空
- 合并后按 `created_at` 降序
- 以 `review_id` 去重，保留最新采集记录

**输出**：`merged_reviews_unique_review_id.csv`

### 3.3 `数据预处理.py`（本层的“标准化清洗主脚本”）

**解决问题**：原始字段存在字符串价格、JSON 字段、缺失值、文本噪声、口径不统一（产品 rating vs 评论 rating）等，无法直接用于建模与 NLP。

**关键清洗与特征化**：

- 价格字段解析：`price_num / original_price_num / list_price / discount_rate`
- 产品字段数值化：`product_rating / product_rating_count / bsr_rank / bought_count_number_clean`
- 供给侧字段结构化：`availability → in_stock_flag / stock_left`
- JSON 字段解析：
  - `images → image_list / main_image / image_count`，并输出明细表 `product_images.csv`
  - `sub_category_ranks → product_subcat_ranks.csv`（抽取真实子类目与 rank）
  - `bullet_points → bullet_points_text / bullet_count`
- 评论口径统一：
  - `rating → review_rating`（避免与产品评分冲突）
  - 评论文本清洗：`review_text_clean` + 文本长度/标点/大写比等特征
  - 变体字段解析：`variant → variant_color / variant_size / variant_style ...`
- 建立事实表与聚合表：
  - `fact_review_enriched.csv`：评论事实表（补充产品维度字段）
  - `agg_product.csv`：ASIN 级评论聚合（均值、方差、verified ratio、helpful votes 等）
  - `agg_product_week.csv`：ASIN×周 的时间粒度聚合（用于周趋势/节奏分析）

**输出目录**：`第1层数据预处理/preprocessed/`

- `products_clean.csv`（产品维表）
- `reviews_clean.csv`（评论清洗表）
- `fact_review_enriched.csv`（评论事实表：review + product dims）
- `agg_product.csv`（ASIN 级聚合）
- `agg_product_week.csv`（ASIN×周聚合）
- `product_images.csv`、`product_subcat_ranks.csv`（明细拆表）

### 3.4 `数据进一步清洗.py`

**解决问题**：Amazon 评论文本中常见“视频播放器垃圾段落”（例如 *The video showcases... This is a modal window.*），会污染词云/主题建模。

**做法**：

- 在 `preprocessed/reviews_clean.csv` 基础上：
  - 移除视频垃圾文本块（保留垃圾标记之后的真实评论）
  - （可选）去停用词，得到更适合词云/主题的文本列

**输出**：`reviews_cleaned_v2.csv`

### 3.5 `主分析表生成.py`

**解决问题**：比赛汇报常需要“商品-评论一张主表”，便于做全局竞品分析与指标筛选。

**做法**：

- 以 `asin` 为键把 `merged_products_unique_asin.csv` 与评论聚合统计（review_count/avg_rating/positive_rate/negative_rate 等）合并
- 生成 `price_num`，并标准化品牌 `brand_lower`

**输出**：`master_analysis_table.csv`

---

## 4. 输出数据/字段代表什么（比赛写法要点）

### 4.1 `products_clean.csv`（产品维表）

用于描述“供给侧”：

- 价格/折扣：`price_num / list_price / discount_rate`
- 口碑与热度：`product_rating / product_rating_count`
- 平台排名：`bsr_rank / bsr_category_norm / best_subcat_rank`
- Listing 质量：`image_count / bullet_count / has_aplus / is_fba`
- 销量代理：`bought_count_number_clean`（注意：不是官方销量，是页面展示的“Bought in past month”等的数值化）

### 4.2 `reviews_clean.csv` & `reviews_cleaned_v2.csv`（评论清洗表）

用于“需求侧（用户声音）”：

- 核心文本：`review_text_clean`（v2 中进一步去噪：`review_text_cleaned_v2`）
- 可信度：`verified_purchase`、`helpful_votes`
- 文本强度：`text_len`、`exclamation_cnt`、`caps_ratio`

### 4.3 `fact_review_enriched.csv`（评论事实表）

用于把**评论与产品属性联动**（例如“高价刀是否更少被吐槽生锈”）：

- review 粒度（每行一条评论）+ 产品维度字段（brand/price_num/bsr_rank/is_fba 等）

### 4.4 `agg_product.csv`（ASIN 级聚合）

用于建模/聚类的“商品级特征”：

- 评论量与评分：`sample_review_n / avg_review_rating_sample / review_rating_std_sample`
- 真实购买占比：`verified_ratio`
- 口碑内容特征：`avg_text_len / has_text_ratio`
- 抓取上限偏差提示：`scrape_cap_10_flag / scrape_cap_100_flag`（用于解释采样偏差）

---

## 5. 在项目书中如何描述本层产物（可直接引用）

建议把本层写成“数据治理层”，按“三件事”写：

1. **合并去重**：跨批次采集数据按主键去重（商品按 `asin`、评论按 `review_id`），保留最新采集版本，保证“一物一档/一评一档”。
2. **字段标准化与结构化**：将价格、日期、JSON 字段（图片/类目 rank/bullet points）解析为可计算字段；把可用信号（库存提示、折扣等）结构化为特征。
3. **星级口径统一与事实表构建**：区分“产品评分（product_rating）”与“评论评分（review_rating）”，并构建 `fact_review_enriched` 以支持跨表联动分析。

---

## 6. 复现运行方式

在 `第1层数据预处理/` 下按顺序运行（典型流程）：

```bash
# 1) 合并去重（商品/评论）
python 商品表合并.py
python 商品评论表合并.py

# 2) 标准化清洗并输出到 preprocessed/
python 数据预处理.py

# 3) （可选）进一步清洗评论文本（去掉视频垃圾段落）
python 数据进一步清洗.py

# 4) （可选）生成比赛汇报用“主分析表”
python 主分析表生成.py
```

---

## 7. 注意事项（写在项目书的“局限性/风险”也很加分）

- 评论与销量信号存在**采样上限与非官方口径**：`bought_count_number_clean` 是页面展示信号，且评论抓取可能存在 top-N cap（脚本已输出 cap flag 供解释）。
- 若后续 NLP 使用 `reviews_cleaned.csv`：请确认你引用的是 `preprocessed/reviews_clean.csv` 还是 `reviews_cleaned_v2.csv`，口径需要统一（建议在项目书中明确“本研究使用去噪后的评论文本列”）。
